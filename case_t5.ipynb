{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33260f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03625327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from test_transformers.src.test2_transformers.models.t5.modeling_t5_2 import T5ForConditionalGeneration\n",
    "# from test_transformers.src.test2_transformers.models.longt5.modeling_longt5 import LongT5ForConditionalGeneration\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c05da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_t5_2 import data_process\n",
    "from inference_t5_2 import keyphrases_selection,calculate_score2\n",
    "from torch.utils.data import DataLoader\n",
    "# from transformers import T5ForConditionalGeneration, LongT5ForConditionalGeneration\n",
    "\n",
    "\n",
    "def get_setting_dict():\n",
    "    setting_dict = {}\n",
    "    setting_dict[\"max_len\"] = 512\n",
    "    \n",
    "    # setting_dict[\"temp_en1\"] = \"Answer the following question by reasoning step-by-step. \"\n",
    "    setting_dict[\"temp_en2\"] = \"Keyword extraction: Extract keywords that reflect the key ideas of this book. \"\n",
    "\n",
    "    setting_dict[\"temp_en1\"] = \"Book:\"\n",
    "    setting_dict[\"temp_de1\"] = \"This book mainly talks about \"\n",
    "    # setting_dict[\"temp_de1\"] = \"Keyphrases: \"\n",
    "    setting_dict[\"temp_de2\"] = \"And in certain sections, this book talks about \"\n",
    "    setting_dict[\"temp_de3\"] = \"Therefore, the keyphrases of this text are \"\n",
    "    setting_dict[\"model\"] = \"base\"\n",
    "    setting_dict[\"enable_filter\"] = False\n",
    "    setting_dict[\"enable_pos\"] = False\n",
    "    setting_dict[\"enable_freq\"] = False\n",
    "    setting_dict[\"enable_att\"] = True\n",
    "    setting_dict[\"position_factor\"] = 1.2e8\n",
    "    setting_dict[\"length_factor\"] = 0.6\n",
    "    return setting_dict\n",
    "\n",
    "def parse_argument(dataset_dir=None, dataset_name=None, batch_size=None, log_dir=None):\n",
    "\n",
    "    if not all([dataset_dir, dataset_name, batch_size, log_dir]):\n",
    "        raise ValueError(\"All arguments (dataset_dir, dataset_name, batch_size, log_dir) must be provided.\")\n",
    "\n",
    "    import argparse\n",
    "    parser = argparse.Namespace(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_name=dataset_name,\n",
    "        batch_size=batch_size,\n",
    "        log_dir=log_dir\n",
    "    )\n",
    "    return parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14a3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"SemEval2017\"\n",
    "args = parse_argument(\n",
    "    dataset_dir=f\"data/{dataset}\", \n",
    "    dataset_name=f\"{dataset}\",\n",
    "    batch_size=128,\n",
    "    log_dir=\"path/to/log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911828e4",
   "metadata": {},
   "source": [
    "# 실험하자자자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d37c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted cross-attention t5 version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import T5ForConditionalGeneration, LongT5ForConditionalGeneration\n",
    "from test_transformers.src.test2_transformers.models.t5.modeling_t5 import T5ForConditionalGeneration\n",
    "setting_dict = get_setting_dict()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-\"+ setting_dict[\"model\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17990e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted cross-attention t5 version\n",
      "[WARNING] '4nmin −' not matched in doc.\n",
      "[WARNING] '4nmin −' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "25\n",
      "[WARNING] 'core 〉' not matched in doc.\n",
      "[WARNING] 'iyi ′' not matched in doc.\n",
      "[WARNING] '⩽ hcore' not matched in doc.\n",
      "[WARNING] 'iyi ″' not matched in doc.\n",
      "[WARNING] 'yi ′' not matched in doc.\n",
      "[WARNING] 'core 〉' not matched in doc.\n",
      "[WARNING] 'iyi ′' not matched in doc.\n",
      "[WARNING] '⩽ hcore' not matched in doc.\n",
      "[WARNING] 'iyi ″' not matched in doc.\n",
      "[WARNING] 'yi ′' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "52\n",
      "[WARNING] 'sc ∼' not matched in doc.\n",
      "[WARNING] 'sc ∼' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "53\n",
      "[WARNING] 'o2 − ions' not matched in doc.\n",
      "[WARNING] 'o2 − ions' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "93\n",
      "[WARNING] '〈 c' not matched in doc.\n",
      "[WARNING] '〈 c' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "94\n",
      "[WARNING] 'å −' not matched in doc.\n",
      "[WARNING] 'q2 ·' not matched in doc.\n",
      "[WARNING] 'q · dij' not matched in doc.\n",
      "[WARNING] 'å −' not matched in doc.\n",
      "[WARNING] 'q2 ·' not matched in doc.\n",
      "[WARNING] 'q · dij' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "113\n",
      "[WARNING] 'implementation .1' not matched in doc.\n",
      "[WARNING] 'implementation .1' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "132\n",
      "[WARNING] 'boundary ∂ ω' not matched in doc.\n",
      "[WARNING] 'boundary ∂ ω' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "154\n",
      "[WARNING] 'new matlab ®' not matched in doc.\n",
      "[WARNING] 'new matlab ®' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "163\n",
      "[WARNING] 'hadoop community ׳' not matched in doc.\n",
      "[WARNING] 'hadoop community ׳' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "168\n",
      "[WARNING] '° c continuous nuclear densities' not matched in doc.\n",
      "[WARNING] '° c continuous nuclear densities' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "180\n",
      "[WARNING] '° c' not matched in doc.\n",
      "[WARNING] '° c' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "193\n",
      "[WARNING] '∼ 520μm silicon carrier wafer' not matched in doc.\n",
      "[WARNING] '∼ 520μm silicon carrier wafer' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 'p :d' not matched in doc.\n",
      "[WARNING] 'l :p :d' not matched in doc.\n",
      "[WARNING] 'order l :p :d' not matched in doc.\n",
      "[WARNING] 'p :d' not matched in doc.\n",
      "[WARNING] 'l :p :d' not matched in doc.\n",
      "[WARNING] 'order l :p :d' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "208\n",
      "[WARNING] '° c' not matched in doc.\n",
      "[WARNING] '° c' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "210\n",
      "[WARNING] 'ε ∞' not matched in doc.\n",
      "[WARNING] 'ε ∞' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "217\n",
      "[WARNING] 'al-o ⋯ h2' not matched in doc.\n",
      "[WARNING] 'al-o ⋯ h2' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "224\n",
      "[WARNING] 'cm ×' not matched in doc.\n",
      "[WARNING] 'cm ×' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "226\n",
      "[WARNING] 'ρλ ≡ λ' not matched in doc.\n",
      "[WARNING] 'ρλ/ρcrit' not matched in doc.\n",
      "[WARNING] 'ωtot ≈' not matched in doc.\n",
      "[WARNING] 'ρλ ≡ λ' not matched in doc.\n",
      "[WARNING] 'ρλ/ρcrit' not matched in doc.\n",
      "[WARNING] 'ωtot ≈' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "247\n",
      "[WARNING] 'ψ ′' not matched in doc.\n",
      "[WARNING] 'ψ ′' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "251\n",
      "[WARNING] 'γγ → π' not matched in doc.\n",
      "[WARNING] 'γγ → π' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "252\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] '− 4cχ' not matched in doc.\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] '− 4cχ' not matched in doc.\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "254\n",
      "[WARNING] '− xhe cluster structure' not matched in doc.\n",
      "[WARNING] '− xhe cluster structure' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "255\n",
      "[WARNING] 'ar →' not matched in doc.\n",
      "[WARNING] 'ar →' not matched in doc.\n",
      "[WARNING] 'cl ∗' not matched in doc.\n",
      "[WARNING] '40k ∗' not matched in doc.\n",
      "[WARNING] '40k ∗' not matched in doc.\n",
      "[WARNING] 'ar →' not matched in doc.\n",
      "[WARNING] 'ar →' not matched in doc.\n",
      "[WARNING] 'cl ∗' not matched in doc.\n",
      "[WARNING] '40k ∗' not matched in doc.\n",
      "[WARNING] '40k ∗' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "259\n",
      "[WARNING] 'cpn −' not matched in doc.\n",
      "[WARNING] '× u' not matched in doc.\n",
      "[WARNING] 'cpn −' not matched in doc.\n",
      "[WARNING] '× u' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "260\n",
      "[WARNING] '12w − fμνafaμν' not matched in doc.\n",
      "[WARNING] 'βw' not matched in doc.\n",
      "[WARNING] '− fγδafaγδ' not matched in doc.\n",
      "[WARNING] 'mfaμν − fαβbfbαβ' not matched in doc.\n",
      "[WARNING] '12w − fμνafaμν' not matched in doc.\n",
      "[WARNING] 'βw' not matched in doc.\n",
      "[WARNING] '− fγδafaγδ' not matched in doc.\n",
      "[WARNING] 'mfaμν − fαβbfbαβ' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "265\n",
      "[WARNING] 'τf ≳' not matched in doc.\n",
      "[WARNING] 'π ±' not matched in doc.\n",
      "[WARNING] 'k ±' not matched in doc.\n",
      "[WARNING] 'τf ≳' not matched in doc.\n",
      "[WARNING] 'π ±' not matched in doc.\n",
      "[WARNING] 'k ±' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "271\n",
      "[WARNING] '∝ exp' not matched in doc.\n",
      "[WARNING] 'γ ⪢' not matched in doc.\n",
      "[WARNING] 'φ ≃ π/2' not matched in doc.\n",
      "[WARNING] '≃ δ' not matched in doc.\n",
      "[WARNING] 'pc ≃ θ' not matched in doc.\n",
      "[WARNING] '− δ' not matched in doc.\n",
      "[WARNING] '∝ exp' not matched in doc.\n",
      "[WARNING] 'γ ⪢' not matched in doc.\n",
      "[WARNING] 'φ ≃ π/2' not matched in doc.\n",
      "[WARNING] '≃ δ' not matched in doc.\n",
      "[WARNING] 'pc ≃ θ' not matched in doc.\n",
      "[WARNING] '− δ' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "277\n",
      "[WARNING] 'q̄q 〉' not matched in doc.\n",
      "[WARNING] 'σ → ππ decay' not matched in doc.\n",
      "[WARNING] 'q̄q 〉' not matched in doc.\n",
      "[WARNING] 'σ → ππ decay' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "278\n",
      "[WARNING] '− ψ' not matched in doc.\n",
      "[WARNING] '− ψ' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "284\n",
      "[WARNING] 's̄gsσ · gs' not matched in doc.\n",
      "[WARNING] 's̄gsσ · gs' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "285\n",
      "[WARNING] 'φv ⊥' not matched in doc.\n",
      "[WARNING] 'b → k' not matched in doc.\n",
      "[WARNING] 'b → k' not matched in doc.\n",
      "[WARNING] 'γ ∗' not matched in doc.\n",
      "[WARNING] 'φv ⊥' not matched in doc.\n",
      "[WARNING] 'b → k' not matched in doc.\n",
      "[WARNING] 'b → k' not matched in doc.\n",
      "[WARNING] 'γ ∗' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "286\n",
      "[WARNING] '→ σ' not matched in doc.\n",
      "[WARNING] 'nn → yθ' not matched in doc.\n",
      "[WARNING] '→ σ' not matched in doc.\n",
      "[WARNING] 'nn → yθ' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "287\n",
      "[WARNING] 'iγ ·' not matched in doc.\n",
      "[WARNING] 'iγ ·' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "288\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] 'k ∗' not matched in doc.\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] 'n ∗' not matched in doc.\n",
      "[WARNING] 'k ∗' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "293\n",
      "[WARNING] 'ξ − −' not matched in doc.\n",
      "[WARNING] 'ξ − −' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "299\n",
      "[WARNING] 'mh ≲' not matched in doc.\n",
      "[WARNING] 'mh ≲' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "302\n",
      "[WARNING] 'r →' not matched in doc.\n",
      "[WARNING] 'λqcd −' not matched in doc.\n",
      "[WARNING] 'ig2tfnc ∫' not matched in doc.\n",
      "[WARNING] '〈 r' not matched in doc.\n",
      "[WARNING] 'r →' not matched in doc.\n",
      "[WARNING] 'λqcd −' not matched in doc.\n",
      "[WARNING] 'ig2tfnc ∫' not matched in doc.\n",
      "[WARNING] '〈 r' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "303\n",
      "[WARNING] 'ss ¯' not matched in doc.\n",
      "[WARNING] 'ss ¯' not matched in doc.\n",
      "[WARNING] 'ss ¯' not matched in doc.\n",
      "[WARNING] 'uu ¯' not matched in doc.\n",
      "[WARNING] 'dd ¯' not matched in doc.\n",
      "[WARNING] 'η ′' not matched in doc.\n",
      "[WARNING] 'ss ¯' not matched in doc.\n",
      "[WARNING] 'b ¯' not matched in doc.\n",
      "[WARNING] 'ss ¯' not matched in doc.\n",
      "[WARNING] 'ss ¯' not matched in doc.\n",
      "[WARNING] 'ss ¯' not matched in doc.\n",
      "[WARNING] 'uu ¯' not matched in doc.\n",
      "[WARNING] 'dd ¯' not matched in doc.\n",
      "[WARNING] 'η ′' not matched in doc.\n",
      "[WARNING] 'ss ¯' not matched in doc.\n",
      "[WARNING] 'b ¯' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "307\n",
      "[WARNING] 'η ′' not matched in doc.\n",
      "[WARNING] 'η ′' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "309\n",
      "[WARNING] 'μp −' not matched in doc.\n",
      "[WARNING] 'π −' not matched in doc.\n",
      "[WARNING] 'ρ −' not matched in doc.\n",
      "[WARNING] 'μp −' not matched in doc.\n",
      "[WARNING] 'π −' not matched in doc.\n",
      "[WARNING] 'ρ −' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "311\n",
      "[WARNING] '× u' not matched in doc.\n",
      "[WARNING] '× u' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "313\n",
      "[WARNING] 'π subbands' not matched in doc.\n",
      "[WARNING] 'π subbands' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "315\n",
      "[WARNING] 'ψi 〉' not matched in doc.\n",
      "[WARNING] 'ψiii 〉' not matched in doc.\n",
      "[WARNING] 'k0 〉' not matched in doc.\n",
      "[WARNING] 'ψi 〉' not matched in doc.\n",
      "[WARNING] 'k − n' not matched in doc.\n",
      "[WARNING] 'ψi 〉' not matched in doc.\n",
      "[WARNING] 'ψiii 〉' not matched in doc.\n",
      "[WARNING] 'k0 〉' not matched in doc.\n",
      "[WARNING] 'ψi 〉' not matched in doc.\n",
      "[WARNING] 'k − n' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "320\n",
      "[WARNING] 'n ⩽' not matched in doc.\n",
      "[WARNING] 'large value' not matched in doc.\n",
      "[WARNING] '≫' not matched in doc.\n",
      "[WARNING] 'w ∞' not matched in doc.\n",
      "[WARNING] '∞ u' not matched in doc.\n",
      "[WARNING] 'n ⩽' not matched in doc.\n",
      "[WARNING] 'large value' not matched in doc.\n",
      "[WARNING] '≫' not matched in doc.\n",
      "[WARNING] 'w ∞' not matched in doc.\n",
      "[WARNING] '∞ u' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "324\n",
      "[WARNING] 'g ∗' not matched in doc.\n",
      "[WARNING] 'g ′' not matched in doc.\n",
      "[WARNING] 'g ″' not matched in doc.\n",
      "[WARNING] 'g ′' not matched in doc.\n",
      "[WARNING] 'g ″' not matched in doc.\n",
      "[WARNING] 'g ′' not matched in doc.\n",
      "[WARNING] 'g ′' not matched in doc.\n",
      "[WARNING] 'g ∗' not matched in doc.\n",
      "[WARNING] 'g ∗' not matched in doc.\n",
      "[WARNING] 'g ′' not matched in doc.\n",
      "[WARNING] 'g ″' not matched in doc.\n",
      "[WARNING] 'g ′' not matched in doc.\n",
      "[WARNING] 'g ″' not matched in doc.\n",
      "[WARNING] 'g ′' not matched in doc.\n",
      "[WARNING] 'g ′' not matched in doc.\n",
      "[WARNING] 'g ∗' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "328\n",
      "[WARNING] 'real component η ′' not matched in doc.\n",
      "[WARNING] 'real component η ′' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "329\n",
      "[WARNING] 'λ −' not matched in doc.\n",
      "[WARNING] 'σr6' not matched in doc.\n",
      "[WARNING] 'λ −' not matched in doc.\n",
      "[WARNING] 'σr6' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "336\n",
      "[WARNING] '° c' not matched in doc.\n",
      "[WARNING] '° c' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "371\n",
      "[WARNING] 'å −' not matched in doc.\n",
      "[WARNING] 'å −' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "380\n",
      "[WARNING] '• rapid urbanization' not matched in doc.\n",
      "[WARNING] '• rapid urbanization' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "389\n",
      "[WARNING] 'tq −' not matched in doc.\n",
      "[WARNING] 'φn n ∈' not matched in doc.\n",
      "[WARNING] 'transformation composition tq −' not matched in doc.\n",
      "[WARNING] 'tq −' not matched in doc.\n",
      "[WARNING] 'φn n ∈' not matched in doc.\n",
      "[WARNING] 'transformation composition tq −' not matched in doc.\n",
      "document idx that does not match the number of candidate and t5 tokenization candidate\n",
      "407\n",
      "candidate_num:  21264\n",
      "examples:  21195\n"
     ]
    }
   ],
   "source": [
    "setting_dict = get_setting_dict()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-\"+ setting_dict[\"model\"])\n",
    "model.to(device)\n",
    "dataset, doc_list, labels, labels_stemed= data_process(setting_dict, args.dataset_dir, args.dataset_name,1,9, model, device)\n",
    "dataloader = DataLoader(dataset, num_workers=12, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "151ef650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "model2 = T5ForConditionalGeneration.from_pretrained(\"t5-\"+ setting_dict[\"model\"])\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aef0d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0\n",
      "37.93\n",
      "41.84\n"
     ]
    }
   ],
   "source": [
    "a= calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,0,1,0,0.,0.05,1.2e8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e1b67c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating::   0%|          | 0/166 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/work/.default/hyeongu/PromptRank_cross_att_gemma2/inference_t5_2.py:305: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  de_input_lens = torch.tensor(dic[\"de_input_len\"]).unsqueeze(1).to(de_input_ids.device)  # (B, 1)\n",
      "Evaluating:: 100%|██████████| 166/166 [00:35<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27040769999091985\n",
      "0.3794407772750872\n",
      "0.41954095070864167\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_rank=keyphrases_selection(setting_dict, doc_list, labels_stemed, labels,  model, dataloader,0.3,0.1,15, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ecd84cf-e799-4a68-93f0-360761aae1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.49\n",
      "19.55\n",
      "21.25\n"
     ]
    }
   ],
   "source": [
    "a=calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,0,1,0,0.,1,1.2e8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e38cbb-94e4-4e81-b266-f54ec9fb1ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.25\n",
      "31.54\n",
      "31.08\n"
     ]
    }
   ],
   "source": [
    "a=calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,0,1,0,0.,0.9,1.2e8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb97a90-6335-47b0-ad31-6458ed301728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.64\n",
      "31.32\n",
      "31.53\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a,b\u001b[38;5;241m=\u001b[39mcalculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.9\u001b[39m,\u001b[38;5;241m1.2e8\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "a=calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,0,1,0,0.,0.9,1.2e8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e55b6e8-d04d-4a70-bc13-ade49ab2d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(new_cand_score, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56ec09-7324-4643-b109-f175294bd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# tensor(...) → int/float로 변환 (필요한 경우)\n",
    "df['doc_id'] = df['doc_id'].apply(lambda x: int(str(x).split('(')[-1].split(')')[0]))\n",
    "df['score'] = df['score'].astype(float)\n",
    "df['whole_att_score'] = df['whole_att_score'].apply(lambda x: float(str(x).split('(')[-1].split(',')[0]))\n",
    "\n",
    "rows = []\n",
    "\n",
    "for doc_id, group in df.groupby('doc_id'):\n",
    "    # Score 기준 상위 15개\n",
    "    top_score = group.nlargest(15, 'score')[['candidate']].reset_index(drop=True)\n",
    "    for i, row in top_score.iterrows():\n",
    "        rows.append({\n",
    "            'doc_id': doc_id,\n",
    "            'rank': i + 1,\n",
    "            'candidate': row['candidate'],\n",
    "            'source': 'score'\n",
    "        })\n",
    "\n",
    "    # Attention 기준 상위 15개\n",
    "    top_att = group.nlargest(15, 'whole_att_score')[['candidate']].reset_index(drop=True)\n",
    "    for i, row in top_att.iterrows():\n",
    "        rows.append({\n",
    "            'doc_id': doc_id,\n",
    "            'rank': i + 1,\n",
    "            'candidate': row['candidate'],\n",
    "            'source': 'attention'\n",
    "        })\n",
    "\n",
    "# 결과 데이터프레임\n",
    "ranked_candidates_df = pd.DataFrame(rows)\n",
    "\n",
    "# 미리보기\n",
    "print(ranked_candidates_df.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "752f7667-5069-4b80-b54f-55e945e370c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc_id  overlap_count  overlap_ratio\n",
      "0       0              0       0.000000\n",
      "1       1              5       0.333333\n",
      "2       2              1       0.066667\n",
      "3       3              1       0.066667\n",
      "4       4              3       0.200000\n",
      "\n",
      "전체 문서 평균 일치도: 0.1481\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# tensor(...) → int/float로 변환 (필요한 경우)\n",
    "df['doc_id'] = df['doc_id'].apply(lambda x: int(str(x).split('(')[-1].split(')')[0]))\n",
    "df['score'] = df['score'].astype(float)\n",
    "df['whole_att_score'] = df['whole_att_score'].apply(lambda x: float(str(x).split('(')[-1].split(',')[0]))\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "results = []\n",
    "\n",
    "for doc_id, group in df.groupby('doc_id'):\n",
    "    top_score = group.nlargest(15, 'score')['candidate']\n",
    "    top_att = group.nlargest(15, 'whole_att_score')['candidate']\n",
    "    \n",
    "    # 공통 후보 개수\n",
    "    overlap = len(set(top_score) & set(top_att))\n",
    "    \n",
    "    results.append({\n",
    "        'doc_id': doc_id,\n",
    "        'overlap_count': overlap,\n",
    "        'overlap_ratio': overlap / 15\n",
    "    })\n",
    "\n",
    "# 결과 데이터프레임으로 정리\n",
    "result_df = pd.DataFrame(results)\n",
    "print(result_df.head())\n",
    "\n",
    "# 평균 일치도\n",
    "mean_overlap = result_df['overlap_ratio'].mean()\n",
    "print(f\"\\n전체 문서 평균 일치도: {mean_overlap:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ece95e10-2442-4546-aebf-9863f1500238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "   doc_id  score_diversity  att_diversity  score_jaccard_diversity  \\\n",
      "0       0         0.725221       0.801539                 0.942593   \n",
      "1       1         0.716994       0.691655                 0.981481   \n",
      "2       2         0.684108       0.754439                 0.988889   \n",
      "3       3         0.546956       0.767488                 0.988889   \n",
      "4       4         0.673508       0.754391                 0.970370   \n",
      "\n",
      "   att_jaccard_diversity  \n",
      "0               1.000000  \n",
      "1               0.970370  \n",
      "2               1.000000  \n",
      "3               0.988889  \n",
      "4               0.961111  \n",
      "평균 생성확률 기반 다양성 (cosine): 0.6977\n",
      "평균 SAM 기반 다양성 (cosine): 0.7613\n",
      "평균 생성확률 기반 다양성 (jaccard): 0.9676\n",
      "평균 SAM 기반 다양성 (jaccard): 0.9903\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def token_overlap_diversity(words):\n",
    "    # 단어들을 토큰으로 분해 (스페이스 기준, 필요시 더 정교하게)\n",
    "    tokenized = [set(w.lower().split()) for w in words]\n",
    "    \n",
    "    overlaps = []\n",
    "    for w1, w2 in itertools.combinations(tokenized, 2):\n",
    "        intersection = w1 & w2\n",
    "        union = w1 | w2\n",
    "        if union:\n",
    "            jaccard = len(intersection) / len(union)\n",
    "            overlaps.append(jaccard)\n",
    "    \n",
    "    if overlaps:\n",
    "        mean_overlap = np.mean(overlaps)\n",
    "        diversity = 1 - mean_overlap\n",
    "    else:\n",
    "        diversity = np.nan\n",
    "\n",
    "    return diversity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "# GPU 사용 가능한지 체크 후 device 지정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# BERT-base 모델 로드 + GPU 할당\n",
    "model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "\n",
    "def extract_float_from_tensor(x):\n",
    "    try:\n",
    "        s = str(x)\n",
    "        import re\n",
    "        match = re.search(r'tensor\\(([\\d\\.\\-e]+)', s)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        else:\n",
    "            return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def extract_int_from_tensor(x):\n",
    "    try:\n",
    "        s = str(x)\n",
    "        import re\n",
    "        match = re.search(r'tensor\\((\\-?\\d+)\\)', s)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            return int(float(s))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['doc_id'] = df['doc_id'].apply(extract_int_from_tensor)\n",
    "df['score'] = df['score'].apply(extract_float_from_tensor)\n",
    "df['whole_att_score'] = df['whole_att_score'].apply(extract_float_from_tensor)\n",
    "df['pos'] = df['pos'].apply(extract_int_from_tensor)\n",
    "\n",
    "def embedding_cosine_matrix(words):\n",
    "    embeddings = model.encode(words, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    cos_sim_matrix = cosine_similarity(embeddings)\n",
    "    return cos_sim_matrix\n",
    "\n",
    "def diversity_score(cos_sim_matrix):\n",
    "    n = cos_sim_matrix.shape[0]\n",
    "    if n < 2:\n",
    "        return np.nan\n",
    "    upper_tri_indices = np.triu_indices(n, k=1)\n",
    "    pairwise_sims = cos_sim_matrix[upper_tri_indices]\n",
    "    mean_sim = np.mean(pairwise_sims)\n",
    "    diversity = 1 - mean_sim\n",
    "    return diversity\n",
    "\n",
    "results = []\n",
    "\n",
    "for doc_id, group in df.groupby('doc_id'):\n",
    "    top_score_words = group.nlargest(10, 'score')['candidate'].tolist()\n",
    "    top_att_words = group.nlargest(10, 'whole_att_score')['candidate'].tolist()\n",
    "\n",
    "    if len(top_score_words) < 2 or len(top_att_words) < 2:\n",
    "        continue\n",
    "\n",
    "    score_cos_sim = embedding_cosine_matrix(top_score_words)\n",
    "    att_cos_sim = embedding_cosine_matrix(top_att_words)\n",
    "\n",
    "    score_div = diversity_score(score_cos_sim)\n",
    "    att_div = diversity_score(att_cos_sim)\n",
    "    score_jaccard_div = token_overlap_diversity(top_score_words)\n",
    "    att_jaccard_div = token_overlap_diversity(top_att_words)\n",
    "\n",
    "    results.append({\n",
    "        'doc_id': doc_id,\n",
    "        'score_diversity': score_div,\n",
    "        'att_diversity': att_div,\n",
    "        'score_jaccard_diversity': score_jaccard_div,\n",
    "        'att_jaccard_diversity': att_jaccard_div\n",
    "    })\n",
    "   \n",
    "diversity_df = pd.DataFrame(results)\n",
    "\n",
    "print(diversity_df.head())\n",
    "\n",
    "print(f\"평균 생성확률 기반 다양성 (cosine): {diversity_df['score_diversity'].mean():.4f}\")\n",
    "print(f\"평균 SAM 기반 다양성 (cosine): {diversity_df['att_diversity'].mean():.4f}\")\n",
    "print(f\"평균 생성확률 기반 다양성 (jaccard): {diversity_df['score_jaccard_diversity'].mean():.4f}\")\n",
    "print(f\"평균 SAM 기반 다양성 (jaccard): {diversity_df['att_jaccard_diversity'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19289294-1028-4b61-8f4d-84ea4778b63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 텐서 문자열 처리\n",
    "df['doc_id'] = df['doc_id'].apply(lambda x: int(str(x).split('(')[-1].split(')')[0]))\n",
    "df['score'] = df['score'].astype(float)\n",
    "df['whole_att_score'] = df['whole_att_score'].apply(lambda x: float(str(x).split('(')[-1].split(',')[0]))\n",
    "df['pos'] = df['pos'].apply(lambda x: int(str(x).split('(')[-1].split(')')[0]))\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "score_top_pos = []\n",
    "att_top_pos = []\n",
    "\n",
    "for doc_id, group in df.groupby('doc_id'):\n",
    "    top_score_pos = group.nlargest(15, 'score')['pos'].tolist()\n",
    "    top_att_pos = group.nlargest(15, 'whole_att_score')['pos'].tolist()\n",
    "    \n",
    "    score_top_pos.extend(top_score_pos)\n",
    "    att_top_pos.extend(top_att_pos)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'pos': score_top_pos + att_top_pos,\n",
    "    'type': ['score top15'] * len(score_top_pos) + ['att top15'] * len(att_top_pos)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=plot_df, x='pos', hue='type', multiple='dodge', shrink=0.8, bins=30)\n",
    "plt.title(\"Histogram of Candidate Positions by Score Type (All Documents)\")\n",
    "plt.xlabel(\"Position in Document (pos)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bdaf78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.71\n",
      "28.4\n",
      "28.44\n"
     ]
    }
   ],
   "source": [
    "new_cand_score = calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,0,0,0,0.,0.6,1.2e8,2)  # 0.15 0.1 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd6e6c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.95\n",
      "31.01\n",
      "31.41\n"
     ]
    }
   ],
   "source": [
    "calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,0,1,0,0.,0.6,1.2e8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7f6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.48\n",
      "33.43\n",
      "33.36\n"
     ]
    }
   ],
   "source": [
    "calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,1,1,0,0.,0.6,1.2e8,2)  # 0.15 0.1 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4e8248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.68\n",
      "33.21\n",
      "33.25\n"
     ]
    }
   ],
   "source": [
    "calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,1,1,0,0.,0.6,1.2e8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2f10cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.98\n",
      "19.34\n",
      "19.62\n",
      "16.67\n",
      "19.73\n",
      "20.23\n",
      "16.27\n",
      "19.16\n",
      "19.84\n",
      "16.84\n",
      "20.08\n",
      "20.16\n",
      "16.44\n",
      "19.38\n",
      "19.69\n",
      "16.95\n",
      "19.65\n",
      "20.19\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('go')\n",
    "    calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,0,1,0,0.6,0.6,1.2e8,i)\n",
    "    calculate_score2(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,1,1,0,0.6,0.6,1.2e8,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26d5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04fba935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(center, sigma):\n",
    "    x = torch.arange(512).float()\n",
    "    weights = torch.exp(-(((x - center) / 50) ** 2) / (2 * sigma**2))\n",
    "    weights = weights.view(1, 1, 1, 512)\n",
    "    # weights[weights <= 0.7] = 0\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b0b79d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3546e-04, 3.9335e-04, 4.6050e-04, 5.3824e-04, 6.2811e-04, 7.3180e-04,\n",
       "        8.5125e-04, 9.8862e-04, 1.1463e-03, 1.3270e-03, 1.5338e-03, 1.7700e-03,\n",
       "        2.0392e-03, 2.3456e-03, 2.6938e-03, 3.0887e-03, 3.5359e-03, 4.0413e-03,\n",
       "        4.6115e-03, 5.2538e-03, 5.9760e-03, 6.7866e-03, 7.6949e-03, 8.7108e-03,\n",
       "        9.8451e-03, 1.1110e-02, 1.2517e-02, 1.4081e-02, 1.5818e-02, 1.7746e-02,\n",
       "        1.9889e-02, 2.2279e-02, 2.4962e-02, 2.8006e-02, 3.1514e-02, 3.5634e-02,\n",
       "        4.0583e-02, 4.6650e-02, 5.4200e-02, 6.3659e-02, 7.5468e-02, 9.0013e-02,\n",
       "        1.0752e-01, 1.2795e-01, 1.5090e-01, 1.7557e-01, 2.0076e-01, 2.2502e-01,\n",
       "        2.4683e-01, 2.6486e-01, 2.7819e-01, 2.8652e-01, 2.9018e-01, 2.9013e-01,\n",
       "        2.8774e-01, 2.8455e-01, 2.8204e-01, 2.8144e-01, 2.8357e-01, 2.8886e-01,\n",
       "        2.9737e-01, 3.0888e-01, 3.2301e-01, 3.3934e-01, 3.5742e-01, 3.7690e-01,\n",
       "        3.9746e-01, 4.1889e-01, 4.4100e-01, 4.6367e-01, 4.8680e-01, 5.1030e-01,\n",
       "        5.3409e-01, 5.5811e-01, 5.8228e-01, 6.0653e-01, 6.3078e-01, 6.5495e-01,\n",
       "        6.7896e-01, 7.0272e-01, 7.2615e-01, 7.4916e-01, 7.7167e-01, 7.9358e-01,\n",
       "        8.1481e-01, 8.3527e-01, 8.5488e-01, 8.7354e-01, 8.9119e-01, 9.0774e-01,\n",
       "        9.2312e-01, 9.3725e-01, 9.5009e-01, 9.6156e-01, 9.7161e-01, 9.8020e-01,\n",
       "        9.8728e-01, 9.9283e-01, 9.9681e-01, 9.9920e-01, 1.0000e+00, 9.9920e-01,\n",
       "        9.9681e-01, 9.9283e-01, 9.8728e-01, 9.8020e-01, 9.7161e-01, 9.6156e-01,\n",
       "        9.5009e-01, 9.3725e-01, 9.2312e-01, 9.0774e-01, 8.9119e-01, 8.7354e-01,\n",
       "        8.5488e-01, 8.3527e-01, 8.1481e-01, 7.9358e-01, 7.7167e-01, 7.4916e-01,\n",
       "        7.2615e-01, 7.0272e-01, 6.7896e-01, 6.5495e-01, 6.3078e-01, 6.0653e-01,\n",
       "        5.8228e-01, 5.5811e-01, 5.3409e-01, 5.1028e-01, 4.8675e-01, 4.6357e-01,\n",
       "        4.4078e-01, 4.1845e-01, 3.9661e-01, 3.7531e-01, 3.5459e-01, 3.3447e-01,\n",
       "        3.1499e-01, 2.9618e-01, 2.7804e-01, 2.6059e-01, 2.4385e-01, 2.2782e-01,\n",
       "        2.1250e-01, 1.9790e-01, 1.8400e-01, 1.7081e-01, 1.5831e-01, 1.4649e-01,\n",
       "        1.3534e-01, 1.2483e-01, 1.1496e-01, 1.0569e-01, 9.7024e-02, 8.8922e-02,\n",
       "        8.1366e-02, 7.4333e-02, 6.7800e-02, 6.1741e-02, 5.6135e-02, 5.0956e-02,\n",
       "        4.6180e-02, 4.1786e-02, 3.7749e-02, 3.4047e-02, 3.0660e-02, 2.7565e-02,\n",
       "        2.4743e-02, 2.2175e-02, 1.9841e-02, 1.7725e-02, 1.5809e-02, 1.4077e-02,\n",
       "        1.2515e-02, 1.1109e-02, 9.8449e-03, 8.7107e-03, 7.6949e-03, 6.7866e-03,\n",
       "        5.9760e-03, 5.2538e-03, 4.6115e-03, 4.0413e-03, 3.5359e-03, 3.0887e-03,\n",
       "        2.6938e-03, 2.3456e-03, 2.0392e-03, 1.7700e-03, 1.5338e-03, 1.3270e-03,\n",
       "        1.1463e-03, 9.8862e-04, 8.5125e-04, 7.3180e-04, 6.2811e-04, 5.3824e-04,\n",
       "        4.6050e-04, 3.9335e-04])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = get_weight(300,0.1)\n",
    "w2 = get_weight(100,0.1)\n",
    "w3 = get_weight(500,0.1)\n",
    "x = torch.arange(512).float()\n",
    "weights = torch.exp(-(((x - 350) / 50) ** 2) / (2 * 0.5**2))\n",
    "weights = weights.view(1, 1, 1, 512)\n",
    "comb= 0.7*weights + 0.1*(w1+w2+w3)\n",
    "combined_weight = comb / comb.amax(dim=-1, keepdim=True) \n",
    "combined_weight[0][0][0][250: 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a01ba7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4013e-45, 1.6816e-44,\n",
       "        2.7465e-43, 4.4309e-42, 6.8619e-41, 1.0210e-39, 1.4597e-38, 2.0050e-37,\n",
       "        2.6460e-36, 3.3551e-35, 4.0873e-34, 4.7841e-33, 5.3801e-32, 5.8133e-31,\n",
       "        6.0349e-30, 6.0193e-29, 5.7683e-28, 5.3111e-27, 4.6983e-26, 3.9934e-25,\n",
       "        3.2610e-24, 2.5586e-23, 1.9287e-22, 1.3969e-21, 9.7210e-21, 6.4993e-20,\n",
       "        4.1750e-19, 2.5768e-18, 1.5280e-17, 8.7054e-17, 4.7653e-16, 2.5062e-15,\n",
       "        1.2664e-14, 6.1484e-14, 2.8680e-13, 1.2853e-12, 5.5346e-12, 2.2897e-11,\n",
       "        9.1015e-11, 3.4759e-10, 1.2754e-09, 4.4963e-09, 1.5230e-08, 4.9564e-08,\n",
       "        1.5498e-07, 4.6557e-07, 1.3438e-06, 3.7267e-06, 9.9295e-06, 2.5419e-05,\n",
       "        6.2521e-05, 1.4775e-04, 3.3546e-04, 7.3180e-04, 1.5338e-03, 3.0887e-03,\n",
       "        5.9760e-03, 1.1109e-02, 1.9841e-02, 3.4047e-02, 5.6135e-02, 8.8922e-02,\n",
       "        1.3534e-01, 1.9790e-01, 2.7804e-01, 3.7531e-01, 4.8675e-01, 6.0653e-01,\n",
       "        7.2615e-01, 8.3527e-01, 9.2312e-01, 9.8020e-01, 1.0000e+00, 9.8020e-01,\n",
       "        9.2312e-01, 8.3527e-01, 7.2615e-01, 6.0653e-01, 4.8675e-01, 3.7531e-01,\n",
       "        2.7804e-01, 1.9790e-01, 1.3534e-01, 8.8922e-02, 5.6135e-02, 3.4047e-02,\n",
       "        1.9841e-02, 1.1109e-02, 5.9760e-03, 3.0887e-03, 1.5338e-03, 7.3180e-04,\n",
       "        3.3546e-04, 1.4775e-04, 6.2521e-05, 2.5419e-05, 9.9295e-06, 3.7267e-06,\n",
       "        1.3438e-06, 4.6557e-07, 1.5498e-07, 4.9564e-08, 1.5230e-08, 4.4963e-09,\n",
       "        1.2754e-09, 3.4759e-10, 9.1015e-11, 2.2897e-11, 5.5346e-12, 1.2853e-12,\n",
       "        2.8680e-13, 6.1484e-14, 1.2664e-14, 2.5062e-15, 4.7653e-16, 8.7054e-17,\n",
       "        1.5280e-17, 2.5768e-18, 4.1750e-19, 6.4993e-20, 9.7210e-21, 1.3969e-21,\n",
       "        1.9287e-22, 2.5586e-23, 3.2610e-24, 3.9934e-25, 4.6983e-26, 5.3111e-27,\n",
       "        5.7683e-28, 6.0193e-29, 6.0349e-30, 5.8133e-31, 5.3801e-32, 4.7841e-33,\n",
       "        4.0873e-34, 3.3551e-35, 2.6460e-36, 2.0050e-37, 1.4597e-38, 1.0210e-39,\n",
       "        6.8619e-41, 4.4309e-42, 2.7465e-43, 1.6816e-44, 1.4013e-45, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1[0][0][0][200: 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beec694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/work/.default/anaconda3/envs/hyeongu_base/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/work/.default/anaconda3/envs/hyeongu_base/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_3482560/3439105126.py\", line 9, in custom_collate_fn\n    batch_dict[key] = torch.tensor([sample[key] for sample in batch])\n  File \"/tmp/ipykernel_3482560/3439105126.py\", line 9, in <listcomp>\n    batch_dict[key] = torch.tensor([sample[key] for sample in batch])\nTypeError: only integer tensors of a single element can be converted to an index\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m islice\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(islice(dataloader,\u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "File \u001b[0;32m~/.default/anaconda3/envs/hyeongu_base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.default/anaconda3/envs/hyeongu_base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1465\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.default/anaconda3/envs/hyeongu_base/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.default/anaconda3/envs/hyeongu_base/lib/python3.10/site-packages/torch/_utils.py:715\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/work/.default/anaconda3/envs/hyeongu_base/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/work/.default/anaconda3/envs/hyeongu_base/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_3482560/3439105126.py\", line 9, in custom_collate_fn\n    batch_dict[key] = torch.tensor([sample[key] for sample in batch])\n  File \"/tmp/ipykernel_3482560/3439105126.py\", line 9, in <listcomp>\n    batch_dict[key] = torch.tensor([sample[key] for sample in batch])\nTypeError: only integer tensors of a single element can be converted to an index\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "for i, batch in enumerate(islice(dataloader,3)):\n",
    "    print(f\"Batch {i}\")\n",
    "    print(batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ca217fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " '▁sensor',\n",
       " 'd',\n",
       " '▁sensors',\n",
       " '▁sensors',\n",
       " '▁target',\n",
       " '▁paper',\n",
       " '▁path',\n",
       " '▁detection',\n",
       " '▁deployment',\n",
       " '▁collaborative',\n",
       " '▁detection',\n",
       " '▁sequential',\n",
       " '▁deployment',\n",
       " '▁traffic']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-\" + setting_dict[\"model\"], model_max_length=512)\n",
    "token_ids = input_ids[loaded_topk_indices[54][6]]\n",
    "\n",
    "tokenizer.convert_ids_to_tokens(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab87a805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6065)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_k = torch.exp(-(((torch.tensor(290.0) - torch.tensor(300.0)) / 50) ** 2) / (2 * (0.2 ** 2)))\n",
    "gaussian_k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2894a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2843625498007968\n",
      "0.3260007212405337\n",
      "0.32029478458049887\n"
     ]
    }
   ],
   "source": [
    "calculate_score(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,1,0,0,1,1,1.2e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "728e9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2858565737051793\n",
      "0.32527948070681567\n",
      "0.3214285714285714\n"
     ]
    }
   ],
   "source": [
    "calculate_score(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,1,0,0,1,1,1.2e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1649e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2843625498007968\n",
      "0.3234763793725208\n",
      "0.31972789115646255\n"
     ]
    }
   ],
   "source": [
    "calculate_score(setting_dict, cosine_similarity_rank,doc_list,labels,labels_stemed,1,0,0,1,1,1.2e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79c24d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=get_score_df(setting_dict,cosine_similarity_rank,doc_list,labels,labels_stemed,1,1,0,0.6,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3369cc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>score</th>\n",
       "      <th>pos</th>\n",
       "      <th>att_score</th>\n",
       "      <th>length</th>\n",
       "      <th>pos2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11245</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>abimael guzman</td>\n",
       "      <td>tensor(-1.0045, dtype=torch.float64)</td>\n",
       "      <td>tensor(75)</td>\n",
       "      <td>tensor(11.2117, dtype=torch.float64)</td>\n",
       "      <td>9</td>\n",
       "      <td>tensor(3.6937)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>peace agreement</td>\n",
       "      <td>tensor(-1.0339, dtype=torch.float64)</td>\n",
       "      <td>tensor(44)</td>\n",
       "      <td>tensor(60.9120, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.5986)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>president alberto fujimori</td>\n",
       "      <td>tensor(-1.2553, dtype=torch.float64)</td>\n",
       "      <td>tensor(65)</td>\n",
       "      <td>tensor(14.1212, dtype=torch.float64)</td>\n",
       "      <td>8</td>\n",
       "      <td>tensor(3.6630)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11248</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>journalist nicolas</td>\n",
       "      <td>tensor(-1.3176, dtype=torch.float64)</td>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>tensor(10.5170, dtype=torch.float64)</td>\n",
       "      <td>6</td>\n",
       "      <td>tensor(3.8470)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11249</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>sunday review</td>\n",
       "      <td>tensor(-1.3277, dtype=torch.float64)</td>\n",
       "      <td>tensor(2)</td>\n",
       "      <td>tensor(14.5800, dtype=torch.float64)</td>\n",
       "      <td>4</td>\n",
       "      <td>tensor(3.4697)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11250</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>general amnesty</td>\n",
       "      <td>tensor(-1.3987, dtype=torch.float64)</td>\n",
       "      <td>tensor(34)</td>\n",
       "      <td>tensor(13.1259, dtype=torch.float64)</td>\n",
       "      <td>5</td>\n",
       "      <td>tensor(3.5679)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11251</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>peruvian government</td>\n",
       "      <td>tensor(-1.4330, dtype=torch.float64)</td>\n",
       "      <td>tensor(59)</td>\n",
       "      <td>tensor(14.9299, dtype=torch.float64)</td>\n",
       "      <td>5</td>\n",
       "      <td>tensor(3.6446)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11252</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>october</td>\n",
       "      <td>tensor(-1.4887, dtype=torch.float64)</td>\n",
       "      <td>tensor(85)</td>\n",
       "      <td>tensor(8.8880, dtype=torch.float64)</td>\n",
       "      <td>4</td>\n",
       "      <td>tensor(3.7243)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>self-dismantling</td>\n",
       "      <td>tensor(-1.5063, dtype=torch.float64)</td>\n",
       "      <td>tensor(198)</td>\n",
       "      <td>tensor(8.7182, dtype=torch.float64)</td>\n",
       "      <td>7</td>\n",
       "      <td>tensor(4.0710)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11254</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>political prisoners</td>\n",
       "      <td>tensor(-1.5811, dtype=torch.float64)</td>\n",
       "      <td>tensor(239)</td>\n",
       "      <td>tensor(25.6284, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(4.1967)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11255</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>armed agitation</td>\n",
       "      <td>tensor(-1.6128, dtype=torch.float64)</td>\n",
       "      <td>tensor(166)</td>\n",
       "      <td>tensor(8.7000, dtype=torch.float64)</td>\n",
       "      <td>4</td>\n",
       "      <td>tensor(3.9728)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11256</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>sabotage</td>\n",
       "      <td>tensor(-1.6696, dtype=torch.float64)</td>\n",
       "      <td>tensor(163)</td>\n",
       "      <td>tensor(15.8954, dtype=torch.float64)</td>\n",
       "      <td>3</td>\n",
       "      <td>tensor(3.9636)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11257</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>possible agreements</td>\n",
       "      <td>tensor(-1.6746, dtype=torch.float64)</td>\n",
       "      <td>tensor(111)</td>\n",
       "      <td>tensor(49.8168, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.8041)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11258</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>popular war</td>\n",
       "      <td>tensor(-1.6843, dtype=torch.float64)</td>\n",
       "      <td>tensor(23)</td>\n",
       "      <td>tensor(34.0236, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.5342)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11259</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>fighting</td>\n",
       "      <td>tensor(-1.7186, dtype=torch.float64)</td>\n",
       "      <td>tensor(156)</td>\n",
       "      <td>tensor(35.1180, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.9421)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11260</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>10-point agreement</td>\n",
       "      <td>tensor(-1.7706, dtype=torch.float64)</td>\n",
       "      <td>tensor(138)</td>\n",
       "      <td>tensor(31.4842, dtype=torch.float64)</td>\n",
       "      <td>3</td>\n",
       "      <td>tensor(3.8869)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11261</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>television program</td>\n",
       "      <td>tensor(-1.7899, dtype=torch.float64)</td>\n",
       "      <td>tensor(5)</td>\n",
       "      <td>tensor(28.4868, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.4789)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11262</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>war</td>\n",
       "      <td>tensor(-1.8151, dtype=torch.float64)</td>\n",
       "      <td>tensor(364)</td>\n",
       "      <td>tensor(17.8020, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(4.5802)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11263</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>talks</td>\n",
       "      <td>tensor(-1.8246, dtype=torch.float64)</td>\n",
       "      <td>tensor(71)</td>\n",
       "      <td>tensor(107.4780, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.6814)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>end</td>\n",
       "      <td>tensor(-1.8559, dtype=torch.float64)</td>\n",
       "      <td>tensor(19)</td>\n",
       "      <td>tensor(45.8820, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.5219)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11265</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>agreement</td>\n",
       "      <td>tensor(-1.8609, dtype=torch.float64)</td>\n",
       "      <td>tensor(268)</td>\n",
       "      <td>tensor(66.6828, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(4.2857)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11266</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>tensor(-1.8974, dtype=torch.float64)</td>\n",
       "      <td>tensor(158)</td>\n",
       "      <td>tensor(30.2328, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.9483)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11267</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>details</td>\n",
       "      <td>tensor(-1.9320, dtype=torch.float64)</td>\n",
       "      <td>tensor(102)</td>\n",
       "      <td>tensor(37.1520, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.7765)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>economic support</td>\n",
       "      <td>tensor(-1.9754, dtype=torch.float64)</td>\n",
       "      <td>tensor(354)</td>\n",
       "      <td>tensor(15.6924, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(4.5495)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11269</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>lima america channel</td>\n",
       "      <td>tensor(-1.9986, dtype=torch.float64)</td>\n",
       "      <td>tensor(130)</td>\n",
       "      <td>tensor(10.7464, dtype=torch.float64)</td>\n",
       "      <td>5</td>\n",
       "      <td>tensor(3.8624)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11270</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>hostilities</td>\n",
       "      <td>tensor(-2.0279, dtype=torch.float64)</td>\n",
       "      <td>tensor(315)</td>\n",
       "      <td>tensor(16.7314, dtype=torch.float64)</td>\n",
       "      <td>3</td>\n",
       "      <td>tensor(4.4299)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11271</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>reliable source</td>\n",
       "      <td>tensor(-2.0461, dtype=torch.float64)</td>\n",
       "      <td>tensor(14)</td>\n",
       "      <td>tensor(44.0964, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.5066)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11272</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>weapons</td>\n",
       "      <td>tensor(-2.0547, dtype=torch.float64)</td>\n",
       "      <td>tensor(191)</td>\n",
       "      <td>tensor(87.3432, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(4.0495)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11273</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>life sentence</td>\n",
       "      <td>tensor(-2.0655, dtype=torch.float64)</td>\n",
       "      <td>tensor(82)</td>\n",
       "      <td>tensor(43.4016, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.7151)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11274</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>normal life</td>\n",
       "      <td>tensor(-2.0683, dtype=torch.float64)</td>\n",
       "      <td>tensor(303)</td>\n",
       "      <td>tensor(44.1576, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(4.3931)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc_id                   candidate  \\\n",
       "11245  tensor(125)              abimael guzman   \n",
       "11246  tensor(125)             peace agreement   \n",
       "11247  tensor(125)  president alberto fujimori   \n",
       "11248  tensor(125)          journalist nicolas   \n",
       "11249  tensor(125)               sunday review   \n",
       "11250  tensor(125)             general amnesty   \n",
       "11251  tensor(125)         peruvian government   \n",
       "11252  tensor(125)                     october   \n",
       "11253  tensor(125)            self-dismantling   \n",
       "11254  tensor(125)         political prisoners   \n",
       "11255  tensor(125)             armed agitation   \n",
       "11256  tensor(125)                    sabotage   \n",
       "11257  tensor(125)         possible agreements   \n",
       "11258  tensor(125)                 popular war   \n",
       "11259  tensor(125)                    fighting   \n",
       "11260  tensor(125)          10-point agreement   \n",
       "11261  tensor(125)          television program   \n",
       "11262  tensor(125)                         war   \n",
       "11263  tensor(125)                       talks   \n",
       "11264  tensor(125)                         end   \n",
       "11265  tensor(125)                   agreement   \n",
       "11266  tensor(125)                   terrorism   \n",
       "11267  tensor(125)                     details   \n",
       "11268  tensor(125)            economic support   \n",
       "11269  tensor(125)        lima america channel   \n",
       "11270  tensor(125)                 hostilities   \n",
       "11271  tensor(125)             reliable source   \n",
       "11272  tensor(125)                     weapons   \n",
       "11273  tensor(125)               life sentence   \n",
       "11274  tensor(125)                 normal life   \n",
       "\n",
       "                                      score          pos  \\\n",
       "11245  tensor(-1.0045, dtype=torch.float64)   tensor(75)   \n",
       "11246  tensor(-1.0339, dtype=torch.float64)   tensor(44)   \n",
       "11247  tensor(-1.2553, dtype=torch.float64)   tensor(65)   \n",
       "11248  tensor(-1.3176, dtype=torch.float64)  tensor(125)   \n",
       "11249  tensor(-1.3277, dtype=torch.float64)    tensor(2)   \n",
       "11250  tensor(-1.3987, dtype=torch.float64)   tensor(34)   \n",
       "11251  tensor(-1.4330, dtype=torch.float64)   tensor(59)   \n",
       "11252  tensor(-1.4887, dtype=torch.float64)   tensor(85)   \n",
       "11253  tensor(-1.5063, dtype=torch.float64)  tensor(198)   \n",
       "11254  tensor(-1.5811, dtype=torch.float64)  tensor(239)   \n",
       "11255  tensor(-1.6128, dtype=torch.float64)  tensor(166)   \n",
       "11256  tensor(-1.6696, dtype=torch.float64)  tensor(163)   \n",
       "11257  tensor(-1.6746, dtype=torch.float64)  tensor(111)   \n",
       "11258  tensor(-1.6843, dtype=torch.float64)   tensor(23)   \n",
       "11259  tensor(-1.7186, dtype=torch.float64)  tensor(156)   \n",
       "11260  tensor(-1.7706, dtype=torch.float64)  tensor(138)   \n",
       "11261  tensor(-1.7899, dtype=torch.float64)    tensor(5)   \n",
       "11262  tensor(-1.8151, dtype=torch.float64)  tensor(364)   \n",
       "11263  tensor(-1.8246, dtype=torch.float64)   tensor(71)   \n",
       "11264  tensor(-1.8559, dtype=torch.float64)   tensor(19)   \n",
       "11265  tensor(-1.8609, dtype=torch.float64)  tensor(268)   \n",
       "11266  tensor(-1.8974, dtype=torch.float64)  tensor(158)   \n",
       "11267  tensor(-1.9320, dtype=torch.float64)  tensor(102)   \n",
       "11268  tensor(-1.9754, dtype=torch.float64)  tensor(354)   \n",
       "11269  tensor(-1.9986, dtype=torch.float64)  tensor(130)   \n",
       "11270  tensor(-2.0279, dtype=torch.float64)  tensor(315)   \n",
       "11271  tensor(-2.0461, dtype=torch.float64)   tensor(14)   \n",
       "11272  tensor(-2.0547, dtype=torch.float64)  tensor(191)   \n",
       "11273  tensor(-2.0655, dtype=torch.float64)   tensor(82)   \n",
       "11274  tensor(-2.0683, dtype=torch.float64)  tensor(303)   \n",
       "\n",
       "                                   att_score  length            pos2  label  \n",
       "11245   tensor(11.2117, dtype=torch.float64)       9  tensor(3.6937)      0  \n",
       "11246   tensor(60.9120, dtype=torch.float64)       2  tensor(3.5986)      1  \n",
       "11247   tensor(14.1212, dtype=torch.float64)       8  tensor(3.6630)      0  \n",
       "11248   tensor(10.5170, dtype=torch.float64)       6  tensor(3.8470)      0  \n",
       "11249   tensor(14.5800, dtype=torch.float64)       4  tensor(3.4697)      0  \n",
       "11250   tensor(13.1259, dtype=torch.float64)       5  tensor(3.5679)      1  \n",
       "11251   tensor(14.9299, dtype=torch.float64)       5  tensor(3.6446)      1  \n",
       "11252    tensor(8.8880, dtype=torch.float64)       4  tensor(3.7243)      0  \n",
       "11253    tensor(8.7182, dtype=torch.float64)       7  tensor(4.0710)      0  \n",
       "11254   tensor(25.6284, dtype=torch.float64)       2  tensor(4.1967)      0  \n",
       "11255    tensor(8.7000, dtype=torch.float64)       4  tensor(3.9728)      0  \n",
       "11256   tensor(15.8954, dtype=torch.float64)       3  tensor(3.9636)      0  \n",
       "11257   tensor(49.8168, dtype=torch.float64)       2  tensor(3.8041)      0  \n",
       "11258   tensor(34.0236, dtype=torch.float64)       2  tensor(3.5342)      1  \n",
       "11259   tensor(35.1180, dtype=torch.float64)       1  tensor(3.9421)      0  \n",
       "11260   tensor(31.4842, dtype=torch.float64)       3  tensor(3.8869)      1  \n",
       "11261   tensor(28.4868, dtype=torch.float64)       2  tensor(3.4789)      0  \n",
       "11262   tensor(17.8020, dtype=torch.float64)       1  tensor(4.5802)      0  \n",
       "11263  tensor(107.4780, dtype=torch.float64)       1  tensor(3.6814)      0  \n",
       "11264   tensor(45.8820, dtype=torch.float64)       1  tensor(3.5219)      0  \n",
       "11265   tensor(66.6828, dtype=torch.float64)       1  tensor(4.2857)      0  \n",
       "11266   tensor(30.2328, dtype=torch.float64)       1  tensor(3.9483)      0  \n",
       "11267   tensor(37.1520, dtype=torch.float64)       1  tensor(3.7765)      0  \n",
       "11268   tensor(15.6924, dtype=torch.float64)       1  tensor(4.5495)      1  \n",
       "11269   tensor(10.7464, dtype=torch.float64)       5  tensor(3.8624)      0  \n",
       "11270   tensor(16.7314, dtype=torch.float64)       3  tensor(4.4299)      0  \n",
       "11271   tensor(44.0964, dtype=torch.float64)       2  tensor(3.5066)      0  \n",
       "11272   tensor(87.3432, dtype=torch.float64)       1  tensor(4.0495)      0  \n",
       "11273   tensor(43.4016, dtype=torch.float64)       2  tensor(3.7151)      0  \n",
       "11274   tensor(44.1576, dtype=torch.float64)       2  tensor(4.3931)      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a['doc_id']==125][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f04075d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>score</th>\n",
       "      <th>pos</th>\n",
       "      <th>att_score</th>\n",
       "      <th>length</th>\n",
       "      <th>pos2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11245</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>abimael guzman</td>\n",
       "      <td>tensor(-5.5979, dtype=torch.float64)</td>\n",
       "      <td>tensor(75)</td>\n",
       "      <td>tensor(0.1065, dtype=torch.float64)</td>\n",
       "      <td>9</td>\n",
       "      <td>tensor(3.6937)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>peace agreement</td>\n",
       "      <td>tensor(-6.0607, dtype=torch.float64)</td>\n",
       "      <td>tensor(44)</td>\n",
       "      <td>tensor(0.3504, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.5986)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>president alberto fujimori</td>\n",
       "      <td>tensor(-7.0750, dtype=torch.float64)</td>\n",
       "      <td>tensor(65)</td>\n",
       "      <td>tensor(0.1077, dtype=torch.float64)</td>\n",
       "      <td>8</td>\n",
       "      <td>tensor(3.6630)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11248</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>journalist nicolas</td>\n",
       "      <td>tensor(-7.3393, dtype=torch.float64)</td>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>tensor(0.1072, dtype=torch.float64)</td>\n",
       "      <td>6</td>\n",
       "      <td>tensor(3.8470)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11249</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>sunday review</td>\n",
       "      <td>tensor(-7.5012, dtype=torch.float64)</td>\n",
       "      <td>tensor(2)</td>\n",
       "      <td>tensor(0.0974, dtype=torch.float64)</td>\n",
       "      <td>4</td>\n",
       "      <td>tensor(3.4697)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11250</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>general amnesty</td>\n",
       "      <td>tensor(-7.8620, dtype=torch.float64)</td>\n",
       "      <td>tensor(34)</td>\n",
       "      <td>tensor(0.1146, dtype=torch.float64)</td>\n",
       "      <td>5</td>\n",
       "      <td>tensor(3.5679)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11251</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>peruvian government</td>\n",
       "      <td>tensor(-8.0883, dtype=torch.float64)</td>\n",
       "      <td>tensor(59)</td>\n",
       "      <td>tensor(0.1362, dtype=torch.float64)</td>\n",
       "      <td>5</td>\n",
       "      <td>tensor(3.6446)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11252</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>october</td>\n",
       "      <td>tensor(-8.2603, dtype=torch.float64)</td>\n",
       "      <td>tensor(85)</td>\n",
       "      <td>tensor(0.0724, dtype=torch.float64)</td>\n",
       "      <td>4</td>\n",
       "      <td>tensor(3.7243)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>self-dismantling</td>\n",
       "      <td>tensor(-8.3250, dtype=torch.float64)</td>\n",
       "      <td>tensor(198)</td>\n",
       "      <td>tensor(0.1262, dtype=torch.float64)</td>\n",
       "      <td>7</td>\n",
       "      <td>tensor(4.0710)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11254</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>armed agitation</td>\n",
       "      <td>tensor(-8.9263, dtype=torch.float64)</td>\n",
       "      <td>tensor(166)</td>\n",
       "      <td>tensor(0.1072, dtype=torch.float64)</td>\n",
       "      <td>4</td>\n",
       "      <td>tensor(3.9728)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11255</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>political prisoners</td>\n",
       "      <td>tensor(-9.0553, dtype=torch.float64)</td>\n",
       "      <td>tensor(239)</td>\n",
       "      <td>tensor(0.2951, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(4.1967)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11256</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>sabotage</td>\n",
       "      <td>tensor(-9.4587, dtype=torch.float64)</td>\n",
       "      <td>tensor(163)</td>\n",
       "      <td>tensor(0.1382, dtype=torch.float64)</td>\n",
       "      <td>3</td>\n",
       "      <td>tensor(3.9636)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11257</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>popular war</td>\n",
       "      <td>tensor(-9.7443, dtype=torch.float64)</td>\n",
       "      <td>tensor(23)</td>\n",
       "      <td>tensor(0.3487, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.5342)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11258</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>possible agreements</td>\n",
       "      <td>tensor(-9.8549, dtype=torch.float64)</td>\n",
       "      <td>tensor(111)</td>\n",
       "      <td>tensor(0.3252, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.8041)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11259</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>fighting</td>\n",
       "      <td>tensor(-10.0140, dtype=torch.float64)</td>\n",
       "      <td>tensor(156)</td>\n",
       "      <td>tensor(0.2406, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.9421)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11260</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>war</td>\n",
       "      <td>tensor(-10.2620, dtype=torch.float64)</td>\n",
       "      <td>tensor(364)</td>\n",
       "      <td>tensor(0.2898, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(4.5802)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11261</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>10-point agreement</td>\n",
       "      <td>tensor(-10.2749, dtype=torch.float64)</td>\n",
       "      <td>tensor(138)</td>\n",
       "      <td>tensor(0.2380, dtype=torch.float64)</td>\n",
       "      <td>3</td>\n",
       "      <td>tensor(3.8869)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11262</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>television program</td>\n",
       "      <td>tensor(-10.3329, dtype=torch.float64)</td>\n",
       "      <td>tensor(5)</td>\n",
       "      <td>tensor(0.2616, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.4789)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11263</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>end</td>\n",
       "      <td>tensor(-10.8523, dtype=torch.float64)</td>\n",
       "      <td>tensor(19)</td>\n",
       "      <td>tensor(0.4248, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.5219)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>tensor(-10.9569, dtype=torch.float64)</td>\n",
       "      <td>tensor(158)</td>\n",
       "      <td>tensor(0.3251, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.9483)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11265</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>talks</td>\n",
       "      <td>tensor(-11.0530, dtype=torch.float64)</td>\n",
       "      <td>tensor(71)</td>\n",
       "      <td>tensor(0.4162, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.6814)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11266</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>agreement</td>\n",
       "      <td>tensor(-11.1308, dtype=torch.float64)</td>\n",
       "      <td>tensor(268)</td>\n",
       "      <td>tensor(0.2687, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(4.2857)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11267</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>economic support</td>\n",
       "      <td>tensor(-11.1408, dtype=torch.float64)</td>\n",
       "      <td>tensor(354)</td>\n",
       "      <td>tensor(0.2523, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(4.5495)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>lima america channel</td>\n",
       "      <td>tensor(-11.1666, dtype=torch.float64)</td>\n",
       "      <td>tensor(130)</td>\n",
       "      <td>tensor(0.1140, dtype=torch.float64)</td>\n",
       "      <td>5</td>\n",
       "      <td>tensor(3.8624)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11269</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>details</td>\n",
       "      <td>tensor(-11.2825, dtype=torch.float64)</td>\n",
       "      <td>tensor(102)</td>\n",
       "      <td>tensor(0.2731, dtype=torch.float64)</td>\n",
       "      <td>1</td>\n",
       "      <td>tensor(3.7765)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11270</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>hostilities</td>\n",
       "      <td>tensor(-11.5073, dtype=torch.float64)</td>\n",
       "      <td>tensor(315)</td>\n",
       "      <td>tensor(0.1794, dtype=torch.float64)</td>\n",
       "      <td>3</td>\n",
       "      <td>tensor(4.4299)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11271</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>reliable source</td>\n",
       "      <td>tensor(-11.9978, dtype=torch.float64)</td>\n",
       "      <td>tensor(14)</td>\n",
       "      <td>tensor(0.3619, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.5066)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11272</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>life sentence</td>\n",
       "      <td>tensor(-12.0948, dtype=torch.float64)</td>\n",
       "      <td>tensor(82)</td>\n",
       "      <td>tensor(0.3825, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(3.7151)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11273</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>guerrilla army</td>\n",
       "      <td>tensor(-12.1677, dtype=torch.float64)</td>\n",
       "      <td>tensor(181)</td>\n",
       "      <td>tensor(0.2314, dtype=torch.float64)</td>\n",
       "      <td>3</td>\n",
       "      <td>tensor(4.0188)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11274</th>\n",
       "      <td>tensor(125)</td>\n",
       "      <td>normal life</td>\n",
       "      <td>tensor(-12.2096, dtype=torch.float64)</td>\n",
       "      <td>tensor(303)</td>\n",
       "      <td>tensor(0.2042, dtype=torch.float64)</td>\n",
       "      <td>2</td>\n",
       "      <td>tensor(4.3931)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc_id                   candidate  \\\n",
       "11245  tensor(125)              abimael guzman   \n",
       "11246  tensor(125)             peace agreement   \n",
       "11247  tensor(125)  president alberto fujimori   \n",
       "11248  tensor(125)          journalist nicolas   \n",
       "11249  tensor(125)               sunday review   \n",
       "11250  tensor(125)             general amnesty   \n",
       "11251  tensor(125)         peruvian government   \n",
       "11252  tensor(125)                     october   \n",
       "11253  tensor(125)            self-dismantling   \n",
       "11254  tensor(125)             armed agitation   \n",
       "11255  tensor(125)         political prisoners   \n",
       "11256  tensor(125)                    sabotage   \n",
       "11257  tensor(125)                 popular war   \n",
       "11258  tensor(125)         possible agreements   \n",
       "11259  tensor(125)                    fighting   \n",
       "11260  tensor(125)                         war   \n",
       "11261  tensor(125)          10-point agreement   \n",
       "11262  tensor(125)          television program   \n",
       "11263  tensor(125)                         end   \n",
       "11264  tensor(125)                   terrorism   \n",
       "11265  tensor(125)                       talks   \n",
       "11266  tensor(125)                   agreement   \n",
       "11267  tensor(125)            economic support   \n",
       "11268  tensor(125)        lima america channel   \n",
       "11269  tensor(125)                     details   \n",
       "11270  tensor(125)                 hostilities   \n",
       "11271  tensor(125)             reliable source   \n",
       "11272  tensor(125)               life sentence   \n",
       "11273  tensor(125)              guerrilla army   \n",
       "11274  tensor(125)                 normal life   \n",
       "\n",
       "                                       score          pos  \\\n",
       "11245   tensor(-5.5979, dtype=torch.float64)   tensor(75)   \n",
       "11246   tensor(-6.0607, dtype=torch.float64)   tensor(44)   \n",
       "11247   tensor(-7.0750, dtype=torch.float64)   tensor(65)   \n",
       "11248   tensor(-7.3393, dtype=torch.float64)  tensor(125)   \n",
       "11249   tensor(-7.5012, dtype=torch.float64)    tensor(2)   \n",
       "11250   tensor(-7.8620, dtype=torch.float64)   tensor(34)   \n",
       "11251   tensor(-8.0883, dtype=torch.float64)   tensor(59)   \n",
       "11252   tensor(-8.2603, dtype=torch.float64)   tensor(85)   \n",
       "11253   tensor(-8.3250, dtype=torch.float64)  tensor(198)   \n",
       "11254   tensor(-8.9263, dtype=torch.float64)  tensor(166)   \n",
       "11255   tensor(-9.0553, dtype=torch.float64)  tensor(239)   \n",
       "11256   tensor(-9.4587, dtype=torch.float64)  tensor(163)   \n",
       "11257   tensor(-9.7443, dtype=torch.float64)   tensor(23)   \n",
       "11258   tensor(-9.8549, dtype=torch.float64)  tensor(111)   \n",
       "11259  tensor(-10.0140, dtype=torch.float64)  tensor(156)   \n",
       "11260  tensor(-10.2620, dtype=torch.float64)  tensor(364)   \n",
       "11261  tensor(-10.2749, dtype=torch.float64)  tensor(138)   \n",
       "11262  tensor(-10.3329, dtype=torch.float64)    tensor(5)   \n",
       "11263  tensor(-10.8523, dtype=torch.float64)   tensor(19)   \n",
       "11264  tensor(-10.9569, dtype=torch.float64)  tensor(158)   \n",
       "11265  tensor(-11.0530, dtype=torch.float64)   tensor(71)   \n",
       "11266  tensor(-11.1308, dtype=torch.float64)  tensor(268)   \n",
       "11267  tensor(-11.1408, dtype=torch.float64)  tensor(354)   \n",
       "11268  tensor(-11.1666, dtype=torch.float64)  tensor(130)   \n",
       "11269  tensor(-11.2825, dtype=torch.float64)  tensor(102)   \n",
       "11270  tensor(-11.5073, dtype=torch.float64)  tensor(315)   \n",
       "11271  tensor(-11.9978, dtype=torch.float64)   tensor(14)   \n",
       "11272  tensor(-12.0948, dtype=torch.float64)   tensor(82)   \n",
       "11273  tensor(-12.1677, dtype=torch.float64)  tensor(181)   \n",
       "11274  tensor(-12.2096, dtype=torch.float64)  tensor(303)   \n",
       "\n",
       "                                 att_score  length            pos2  label  \n",
       "11245  tensor(0.1065, dtype=torch.float64)       9  tensor(3.6937)      0  \n",
       "11246  tensor(0.3504, dtype=torch.float64)       2  tensor(3.5986)      1  \n",
       "11247  tensor(0.1077, dtype=torch.float64)       8  tensor(3.6630)      0  \n",
       "11248  tensor(0.1072, dtype=torch.float64)       6  tensor(3.8470)      0  \n",
       "11249  tensor(0.0974, dtype=torch.float64)       4  tensor(3.4697)      0  \n",
       "11250  tensor(0.1146, dtype=torch.float64)       5  tensor(3.5679)      1  \n",
       "11251  tensor(0.1362, dtype=torch.float64)       5  tensor(3.6446)      1  \n",
       "11252  tensor(0.0724, dtype=torch.float64)       4  tensor(3.7243)      0  \n",
       "11253  tensor(0.1262, dtype=torch.float64)       7  tensor(4.0710)      0  \n",
       "11254  tensor(0.1072, dtype=torch.float64)       4  tensor(3.9728)      0  \n",
       "11255  tensor(0.2951, dtype=torch.float64)       2  tensor(4.1967)      0  \n",
       "11256  tensor(0.1382, dtype=torch.float64)       3  tensor(3.9636)      0  \n",
       "11257  tensor(0.3487, dtype=torch.float64)       2  tensor(3.5342)      1  \n",
       "11258  tensor(0.3252, dtype=torch.float64)       2  tensor(3.8041)      0  \n",
       "11259  tensor(0.2406, dtype=torch.float64)       1  tensor(3.9421)      0  \n",
       "11260  tensor(0.2898, dtype=torch.float64)       1  tensor(4.5802)      0  \n",
       "11261  tensor(0.2380, dtype=torch.float64)       3  tensor(3.8869)      1  \n",
       "11262  tensor(0.2616, dtype=torch.float64)       2  tensor(3.4789)      0  \n",
       "11263  tensor(0.4248, dtype=torch.float64)       1  tensor(3.5219)      0  \n",
       "11264  tensor(0.3251, dtype=torch.float64)       1  tensor(3.9483)      0  \n",
       "11265  tensor(0.4162, dtype=torch.float64)       1  tensor(3.6814)      0  \n",
       "11266  tensor(0.2687, dtype=torch.float64)       1  tensor(4.2857)      0  \n",
       "11267  tensor(0.2523, dtype=torch.float64)       2  tensor(4.5495)      1  \n",
       "11268  tensor(0.1140, dtype=torch.float64)       5  tensor(3.8624)      0  \n",
       "11269  tensor(0.2731, dtype=torch.float64)       1  tensor(3.7765)      0  \n",
       "11270  tensor(0.1794, dtype=torch.float64)       3  tensor(4.4299)      0  \n",
       "11271  tensor(0.3619, dtype=torch.float64)       2  tensor(3.5066)      0  \n",
       "11272  tensor(0.3825, dtype=torch.float64)       2  tensor(3.7151)      0  \n",
       "11273  tensor(0.2314, dtype=torch.float64)       3  tensor(4.0188)      1  \n",
       "11274  tensor(0.2042, dtype=torch.float64)       2  tensor(4.3931)      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a['doc_id']==125][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2a5c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(\"result/duc_result_weight_0.5_0.5_self_one.csv\", index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyeongu_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
